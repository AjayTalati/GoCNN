{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'go_datafile_reader' from 'go_datafile_reader.pyc'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import go_datafile_reader\n",
    "import model\n",
    "import numpy as np\n",
    "reload(model)\n",
    "reload(go_datafile_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/justin/Programming/GoAI/MovePredictionCNN/data/input/test\"\n",
    "ckpt_path = \"/home/justin/Programming/GoAI/MovePredictionCNN/data/working/board_eval_cnn_5layer.ckpt\"\n",
    "RECORD_BYTES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_count = 0\n",
    "data_files = []\n",
    "for subdir, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        filepath = subdir + os.sep + file\n",
    "        if filepath.endswith(\".dat\"):\n",
    "            data_files.append(filepath)\n",
    "            file_count+=1\n",
    "print file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = go_datafile_reader.GoDatafileReader(data_files)\n",
    "batch_aggregator = go_datafile_reader.BatchAggregator(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, ownership = model.place_holders()\n",
    "y_conv = model.model(x)\n",
    "loss = model.loss_function(ownership, y_conv)\n",
    "\n",
    "train_op = model.train_step(loss)\n",
    "\n",
    "\n",
    "prediction = tf.round(y_conv)\n",
    "correct_prediction = tf.equal(ownership, prediction)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver(tf.all_variables())\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got to end of mega batch, reinitializing...\n",
      "2468.22 0.845152\n",
      "Saving Checkpoint...\n",
      "2270.2 0.855956\n",
      "2440.9 0.843823\n",
      "2654.3 0.83108\n",
      "2831.8 0.814903\n",
      "2537.17 0.835568\n",
      "2536.57 0.837673\n",
      "2597.35 0.833019\n",
      "2656.67 0.832022\n",
      "2295.22 0.851025\n",
      "2773.33 0.827258\n",
      "2262.35 0.853407\n",
      "2496.81 0.841717\n",
      "2610.25 0.829584\n",
      "2386.69 0.846039\n",
      "2589.55 0.831911\n",
      "2172.32 0.866648\n",
      "2469.6 0.83856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-658757b41993>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_conv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mownership\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mownership\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \"\"\"\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   2726\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2727\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 2728\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/justin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 404\u001b[1;33m                                target_list)\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(100000):\n",
    "    x_batch, y_batch = batch_aggregator.get_batch(50)\n",
    "    _, loss_value, y_value = sess.run([train_op, loss, y_conv], feed_dict={x:x_batch, ownership:y_batch})\n",
    "    if k % 10 == 0:\n",
    "        acc = accuracy.eval(feed_dict={x:x_batch, ownership:y_batch})\n",
    "        print loss_value, acc\n",
    "    if k % 1000 == 0:\n",
    "        print \"Saving Checkpoint...\"\n",
    "        saver.save(sess, ckpt_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = batch_aggregator.get_batch(50)\n",
    "y_val, y_preds = sess.run([y_conv, prediction], feed_dict={x:x_batch, ownership:y_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************   1111111101000000000   1111111110000000000\n",
      "*******************   1111101111100000001   1111101111000000000\n",
      "*111*1*************   0111010010000000111   0111000010000000001\n",
      "*1000********0**1**   0100001111000001111   0100001111000000111\n",
      "*00****************   0000010011000001111   0000011010000101111\n",
      "**10***********1***   0010000011000011111   1000001011000111111\n",
      "*************0*****   1100111001100011111   1100111000000011111\n",
      "*******************   0110011110010011111   0110001010001011111\n",
      "******1************   0011111111010011111   0011101111011111111\n",
      "**0***100**********   0000111001001000111   0000111000001111111\n",
      "******110*******1**   0000001101011011111   0000001100011111111\n",
      "***0111011*********   0000111011111011111   0000111011111111101\n",
      "***0100001*********   0000100001111101101   0000100001111111101\n",
      "***00100*01********   0000010001111110000   0000010011111111101\n",
      "*****1**011********   0000111001111100000   0000111001111111000\n",
      "*****1**00011*0*0**   0011111000011100000   0000111100011101000\n",
      "***1******100******   0111111100000000000   0001111110000100000\n",
      "*******************   1111111100000000000   0011111100000000000\n",
      "*******************   0111111100000000010   0111111000000000000\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "y_pred = np.reshape(y_preds[idx], [19,19])\n",
    "y_true = np.reshape(y_batch[idx], [19,19])\n",
    "feature_cube = x_batch[idx]\n",
    "\n",
    "for i in xrange(19):\n",
    "    current_row = \"\"\n",
    "    for j in xrange(19):\n",
    "        b_sum = feature_cube[i][j][0] + feature_cube[i][j][1] + feature_cube[i][j][2]\n",
    "        w_sum = feature_cube[i][j][3] + feature_cube[i][j][4] + feature_cube[i][j][5]\n",
    "        if b_sum > 0:\n",
    "            current_row += '1'\n",
    "        elif w_sum > 0:\n",
    "            current_row += '0'\n",
    "        else:\n",
    "            current_row += '*'\n",
    "    current_row += \"   \"\n",
    "    for j in xrange(19):\n",
    "        if y_pred[i][j] == 1:\n",
    "            current_row += '1'\n",
    "        elif y_pred[i][j] == 0:\n",
    "            current_row += '0'\n",
    "        else:\n",
    "            current_row += '*'\n",
    "    current_row += \"   \"\n",
    "    for j in xrange(19):\n",
    "        if y_true[i][j] == 1:\n",
    "            current_row += '1'\n",
    "        elif y_true[i][j] == 0:\n",
    "            current_row += '0'\n",
    "        else:\n",
    "            current_row += '*'\n",
    "    print current_row\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "208\n",
      "267\n",
      "266\n",
      "252\n",
      "252\n",
      "269\n",
      "294\n",
      "240\n",
      "252\n",
      "277\n",
      "269\n",
      "285\n",
      "260\n",
      "274\n",
      "328\n",
      "309\n",
      "238\n",
      "314\n",
      "270\n",
      "253\n",
      "283\n",
      "245\n",
      "242\n",
      "324\n",
      "238\n",
      "266\n",
      "223\n",
      "235\n",
      "235\n",
      "254\n",
      "298\n",
      "318\n",
      "251\n",
      "258\n",
      "267\n",
      "241\n",
      "259\n",
      "231\n",
      "279\n",
      "312\n",
      "246\n",
      "296\n",
      "221\n",
      "286\n",
      "243\n",
      "266\n",
      "256\n",
      "241\n",
      "308\n",
      "241\n",
      "294\n",
      "292\n",
      "279\n",
      "276\n",
      "345\n",
      "265\n",
      "287\n",
      "252\n",
      "264\n",
      "258\n",
      "267\n",
      "238\n",
      "254\n",
      "243\n",
      "265\n",
      "224\n",
      "265\n",
      "301\n",
      "262\n",
      "225\n",
      "235\n",
      "231\n",
      "314\n",
      "316\n",
      "267\n",
      "322\n",
      "277\n",
      "246\n",
      "262\n",
      "242\n",
      "280\n",
      "230\n",
      "280\n",
      "290\n",
      "228\n",
      "240\n",
      "261\n",
      "314\n",
      "306\n",
      "238\n",
      "258\n",
      "272\n",
      "291\n",
      "249\n",
      "261\n",
      "249\n",
      "261\n",
      "271\n",
      "255\n",
      "288\n",
      "258\n",
      "242\n",
      "246\n",
      "301\n",
      "285\n",
      "324\n",
      "265\n",
      "337\n",
      "363\n",
      "254\n",
      "249\n",
      "220\n",
      "237\n",
      "237\n",
      "264\n",
      "246\n",
      "244\n",
      "244\n",
      "297\n",
      "302\n",
      "285\n",
      "305\n",
      "275\n",
      "261\n",
      "257\n",
      "244\n",
      "242\n",
      "280\n",
      "251\n",
      "290\n",
      "268\n",
      "333\n",
      "296\n",
      "266\n",
      "284\n",
      "263\n",
      "287\n",
      "321\n",
      "288\n",
      "271\n",
      "263\n",
      "257\n",
      "287\n",
      "249\n",
      "236\n",
      "342\n",
      "282\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "old_index = 0\n",
    "old_k = 0\n",
    "for k in range(40000):\n",
    "    final_state, _, feature_cube = reader.read_sample()\n",
    "    if reader.index_of_file != old_index:\n",
    "        print k-old_k\n",
    "        old_k = k\n",
    "        old_index = reader.index_of_file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
